{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Husseinalia99/My-graduation-project/blob/main/efficientnetb5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "JMA-lS3yLXxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --root-user-action=ignore\n",
        "!pip install pandas\n",
        "\n",
        "!pip install split_folders"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:51:33.929001Z",
          "iopub.execute_input": "2023-06-19T17:51:33.929403Z"
        },
        "trusted": true,
        "id": "YI1_sUKbLXx_",
        "outputId": "550816b2-3169-4f7e-d71a-5446f965ee11"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n\u001b[0m^C\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2022.1)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.6)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.1.2)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../input/skin-diseases-image-dataset/IMG_CLASSES"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:28:59.553191Z",
          "iopub.execute_input": "2023-06-19T17:28:59.553624Z",
          "iopub.status.idle": "2023-06-19T17:29:00.689590Z",
          "shell.execute_reply.started": "2023-06-19T17:28:59.553582Z",
          "shell.execute_reply": "2023-06-19T17:29:00.688239Z"
        },
        "trusted": true,
        "id": "79AYryDcLXyD",
        "outputId": "ef32d93c-9818-4980-8adc-2568b30af471"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "'1. Eczema 1677'\n'10. Warts Molluscum and other Viral Infections - 2103'\n'2. Melanoma 15.75k'\n'3. Atopic Dermatitis - 1.25k'\n'4. Basal Cell Carcinoma (BCC) 3323'\n'5. Melanocytic Nevi (NV) - 7970'\n'6. Benign Keratosis-like Lesions (BKL) 2624'\n'7. Psoriasis pictures Lichen Planus and related diseases - 2k'\n'8. Seborrheic Keratoses and other Benign Tumors - 1.8k'\n'9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k'\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "import os\n",
        "\n",
        "os.makedirs('output')\n",
        "os.makedirs('output/train')\n",
        "os.makedirs('output/val')\n",
        "os.makedirs('output/test')\n",
        "\n",
        "loc = \"../input/skin-diseases-image-dataset/IMG_CLASSES/\"\n",
        "\n",
        "splitfolders.ratio(loc,output = \"output\",seed = 42,ratio = (0.80,.1,.1))"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.691371Z",
          "iopub.execute_input": "2023-06-19T17:29:00.691870Z",
          "iopub.status.idle": "2023-06-19T17:29:00.797139Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.691823Z",
          "shell.execute_reply": "2023-06-19T17:29:00.789072Z"
        },
        "trusted": true,
        "id": "WIMVsd5YLXyE",
        "outputId": "e68aaf72-6ad5-4a42-e9b3-8e37b69f58bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27/206454462.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'splitfolders'"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'splitfolders'",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> In kaggle we need to create a directory for our data after splitting but if we do this using jupyter notebook on our PC/laptop,we can just specify the input path and output path."
      ],
      "metadata": {
        "id": "lpnXVE2RLXyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirpath,dirname,filename in os.walk(\"./output\"):\n",
        "    print(f\"There are {len(dirname)} and {len(filename)} in '{dirpath}'.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.798548Z",
          "iopub.status.idle": "2023-06-19T17:29:00.799901Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.799543Z",
          "shell.execute_reply": "2023-06-19T17:29:00.799574Z"
        },
        "trusted": true,
        "id": "ZY7946EDLXyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> After modifying our input data and before the start of modelling its always best to visualize some random images of the dataset"
      ],
      "metadata": {
        "id": "q87L-0_OLXyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mping\n",
        "import random\n",
        "\n",
        "def plot_random_image(target_dir,target_class):\n",
        "    target_folder = target_dir + target_class\n",
        "    random_image = random.sample(os.listdir(target_folder),1)\n",
        "    img = mping.imread(target_folder + \"/\" + random_image[0])\n",
        "    plt.imshow(img)\n",
        "    plt.title(target_class)\n",
        "    plt.axis(\"off\");\n",
        "    return img\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.801591Z",
          "iopub.status.idle": "2023-06-19T17:29:00.802172Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.801892Z",
          "shell.execute_reply": "2023-06-19T17:29:00.801917Z"
        },
        "trusted": true,
        "id": "svz4_79VLXyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "fig.add_subplot(2,2,1)\n",
        "img_1 = plot_random_image(target_dir = \"./output/test/\",target_class = \"2. Melanoma 15.75k\")\n",
        "fig.add_subplot(2,2,2)\n",
        "img_2 = plot_random_image(target_dir = \"./output/test/\",target_class = \"4. Basal Cell Carcinoma (BCC) 3323\")\n",
        "fig.add_subplot(2,2,3)\n",
        "img_3 = plot_random_image(target_dir = \"./output/test/\",target_class = \"5. Melanocytic Nevi (NV) - 7970\")\n",
        "fig.add_subplot(2,2,4)\n",
        "img4 = plot_random_image(target_dir = \"./output/test/\",target_class = \"1. Eczema 1677\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.803709Z",
          "iopub.status.idle": "2023-06-19T17:29:00.804246Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.803973Z",
          "shell.execute_reply": "2023-06-19T17:29:00.803996Z"
        },
        "trusted": true,
        "id": "zhPvlQEJLXyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Modelling***"
      ],
      "metadata": {
        "id": "m6CNqoFNLXyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.805822Z",
          "iopub.status.idle": "2023-06-19T17:29:00.806459Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.806111Z",
          "shell.execute_reply": "2023-06-19T17:29:00.806136Z"
        },
        "trusted": true,
        "id": "Dro8n_8zLXyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.808122Z",
          "iopub.status.idle": "2023-06-19T17:29:00.808668Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.808394Z",
          "shell.execute_reply": "2023-06-19T17:29:00.808418Z"
        },
        "trusted": true,
        "id": "1PaL3zEZLXyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> When we use mixed_precision training the computation speed is increased by 3x times based on the GPU available. Mixed precision enables training using float16 half-precision variables whenever possible."
      ],
      "metadata": {
        "id": "gc7-dWIILXyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "train_dir = \"./output/train\"\n",
        "test_dir =  \"./output/test\"\n",
        "val_dir = \"./output/val\"\n",
        "\n",
        "train_data = image_dataset_from_directory(train_dir,label_mode = \"categorical\",\n",
        "                                          image_size = (224,224),batch_size = 32,\n",
        "                                         shuffle = True,seed = 42)\n",
        "test_data = image_dataset_from_directory(test_dir,label_mode = \"categorical\",\n",
        "                                          image_size = (224,224),batch_size = 32,\n",
        "                                         shuffle = False,seed = 42)\n",
        "val_data = image_dataset_from_directory(val_dir,label_mode = \"categorical\",\n",
        "                                          image_size = (224,224),batch_size = 32,\n",
        "                                         shuffle = False,seed = 42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.810331Z",
          "iopub.status.idle": "2023-06-19T17:29:00.810894Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.810598Z",
          "shell.execute_reply": "2023-06-19T17:29:00.810622Z"
        },
        "trusted": true,
        "id": "biuaDp-RLXyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> image_dataset_from_directory() imports and converts our input data into tf.data.Dataset format and it is generally faster than ImageDataGenerator()."
      ],
      "metadata": {
        "id": "Uw1G3CAoLXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.class_names\n",
        "print(len(class_names))\n",
        "print(class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.812064Z",
          "iopub.status.idle": "2023-06-19T17:29:00.812613Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.812325Z",
          "shell.execute_reply": "2023-06-19T17:29:00.812349Z"
        },
        "trusted": true,
        "id": "v1CdB6nLLXyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 6,\n",
        "                                             min_delta = 0.0001)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\",factor = 0.2,\n",
        "                                                patience = 4,min_lr = 1e-7)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.814027Z",
          "iopub.status.idle": "2023-06-19T17:29:00.814581Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.814282Z",
          "shell.execute_reply": "2023-06-19T17:29:00.814305Z"
        },
        "trusted": true,
        "id": "i996YmdDLXyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * Earlystopping callback stops training when the model stops improving in terms of validation loss(in this case) and prevents overfitting.\n",
        "> * ReduceLROnPlateau reduces the learning rate by 5x(in this case) whenever validation loss is not improving.\n",
        "> * With the combination of Earlystopping and ReduceLROnPlateau callback when can train our model for any number of epochs without worrying about overfitting.\n"
      ],
      "metadata": {
        "id": "oo1HqId6LXyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "test_data = test_data.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_data = val_data.prefetch(buffer_size = tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.815835Z",
          "iopub.status.idle": "2023-06-19T17:29:00.816357Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.816086Z",
          "shell.execute_reply": "2023-06-19T17:29:00.816111Z"
        },
        "trusted": true,
        "id": "RxuECAwULXyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Data is prefetched to reduce computation time."
      ],
      "metadata": {
        "id": "6acaG3MYLXyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB5(include_top = False)\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.818346Z",
          "iopub.status.idle": "2023-06-19T17:29:00.818908Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.818609Z",
          "shell.execute_reply": "2023-06-19T17:29:00.818633Z"
        },
        "trusted": true,
        "id": "lnKglBFlLXyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> First we are going to be training feature extractor EfficientNetB5 model. Feature extractor transfer learning involves using the pretrained weights of a model trained on another dataset similar to own for our own problem. Here the output layer of pretrained model is modified according our own problem."
      ],
      "metadata": {
        "id": "gtJZhuupLXyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_num,layer in enumerate(base_model.layers):\n",
        "    print(layer_num,layer.name,layer.trainable)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.820506Z",
          "iopub.status.idle": "2023-06-19T17:29:00.821046Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.820771Z",
          "shell.execute_reply": "2023-06-19T17:29:00.820795Z"
        },
        "trusted": true,
        "id": "sjVcK1_rLXyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> As we can see EfficientNetB5 consists of 575 layers without including the output layer and the most important thing to note among these layers is the rescaling layer present right after the input layer,this means that we dont have to rescale our data during preprocessing."
      ],
      "metadata": {
        "id": "igADPrEsLXyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "data_aug = tf.keras.Sequential([\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomFlip(\"horizontal\")\n",
        "],name = \"data_augmentation_layer\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.826175Z",
          "iopub.status.idle": "2023-06-19T17:29:00.826644Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.826422Z",
          "shell.execute_reply": "2023-06-19T17:29:00.826443Z"
        },
        "trusted": true,
        "id": "PtPWpTOILXyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Data augmentation is used here to prevent overfitting, we can experiment without data augmentation and check whether the model overfits or not,but since we are using a transfer learning Architecture such as EfficientNet,its best to include data augmentation since the probability of our model overfitting is very high."
      ],
      "metadata": {
        "id": "hLdrmUZ6LXyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape = (224,224,3),name = \"input_layer\")\n",
        "x = data_aug(inputs)\n",
        "x = base_model(x)\n",
        "x = layers.GlobalAvgPool2D(name = \"pooling_layer\")(x)\n",
        "x = layers.Dense(32,activation = \"relu\",kernel_initializer = tf.keras.initializers.he_normal())(x)\n",
        "x = layers.Dense(10)(x)\n",
        "outputs = layers.Activation(\"softmax\",dtype = tf.float32)(x)\n",
        "model = tf.keras.Model(inputs,outputs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.828409Z",
          "iopub.status.idle": "2023-06-19T17:29:00.828900Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.828640Z",
          "shell.execute_reply": "2023-06-19T17:29:00.828660Z"
        },
        "trusted": true,
        "id": "k3mhZQ1cLXyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.830828Z",
          "iopub.status.idle": "2023-06-19T17:29:00.831279Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.831061Z",
          "shell.execute_reply": "2023-06-19T17:29:00.831081Z"
        },
        "trusted": true,
        "id": "KxON9YydLXyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_num,layer in enumerate(model.layers):\n",
        "    print(layer_num,layer.name,layer.trainable,layer.dtype,layer.dtype_policy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.832896Z",
          "iopub.status.idle": "2023-06-19T17:29:00.833348Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.833130Z",
          "shell.execute_reply": "2023-06-19T17:29:00.833151Z"
        },
        "trusted": true,
        "id": "f17CuCDkLXyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We can clearly see here that mixed_precision policy is implemented and our EfficientNetB5 model is completely frozen. Now we can compile and fit our model."
      ],
      "metadata": {
        "id": "Q8-72-41LXyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),optimizer = tf.keras.optimizers.Adam(),\n",
        "             metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.834906Z",
          "iopub.status.idle": "2023-06-19T17:29:00.835345Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.835133Z",
          "shell.execute_reply": "2023-06-19T17:29:00.835153Z"
        },
        "trusted": true,
        "id": "dwasFHLkLXyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model.fit(train_data,epochs = 15,steps_per_epoch = len(train_data),\n",
        "                     validation_data = val_data,validation_steps = int(0.25*len(val_data)),\n",
        "                     callbacks = [early_stop,reduce_lr])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.836795Z",
          "iopub.status.idle": "2023-06-19T17:29:00.837233Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.837019Z",
          "shell.execute_reply": "2023-06-19T17:29:00.837040Z"
        },
        "trusted": true,
        "id": "jeLcs3z8LXyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Accuracy\",model.evaluate(val_data))\n",
        "print(\"Testing Accuracy\",model.evaluate(test_data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.838476Z",
          "iopub.status.idle": "2023-06-19T17:29:00.838929Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.838708Z",
          "shell.execute_reply": "2023-06-19T17:29:00.838734Z"
        },
        "trusted": true,
        "id": "UZXTzfWCLXyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.841765Z",
          "iopub.status.idle": "2023-06-19T17:29:00.842675Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.842392Z",
          "shell.execute_reply": "2023-06-19T17:29:00.842431Z"
        },
        "trusted": true,
        "id": "OU3IPpeuLXyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.844222Z",
          "iopub.status.idle": "2023-06-19T17:29:00.845164Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.844923Z",
          "shell.execute_reply": "2023-06-19T17:29:00.844946Z"
        },
        "trusted": true,
        "id": "sO8wAAdALXyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * Training Accuracy - 74.4%\n",
        "> * Testing Accuracy  - 71.2%\n",
        "> * Validation Accuracy - 71.7%\n",
        "\n",
        "> Note: Specified number of epochs as 15 but training stopped at 12 and it wasn't beacuse of earlystopping callback,not sure why it stopped early, if you got any ideas please do mention it."
      ],
      "metadata": {
        "id": "-dHSxfOOLXyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuned EfficientNetB5"
      ],
      "metadata": {
        "id": "C2IMLuR_LXyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.846499Z",
          "iopub.status.idle": "2023-06-19T17:29:00.847122Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.846734Z",
          "shell.execute_reply": "2023-06-19T17:29:00.846755Z"
        },
        "trusted": true,
        "id": "13rMML6sLXyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now in order to improve our model's performance we unfreeze the top 30 layers closer to the output layer and let them train on our data instead of using pre-trained weights."
      ],
      "metadata": {
        "id": "X04yBmYfLXyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_num,layer in enumerate(model.layers):\n",
        "    print(layer_num,layer.name,layer.trainable,layer.dtype_policy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.850137Z",
          "iopub.status.idle": "2023-06-19T17:29:00.850588Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.850372Z",
          "shell.execute_reply": "2023-06-19T17:29:00.850393Z"
        },
        "trusted": true,
        "id": "VEnkHbPyLXyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_num,layer in enumerate(base_model.layers):\n",
        "    print(layer_num,layer.name,layer.trainable)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.851925Z",
          "iopub.status.idle": "2023-06-19T17:29:00.852373Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.852152Z",
          "shell.execute_reply": "2023-06-19T17:29:00.852172Z"
        },
        "trusted": true,
        "id": "N3NaAWBxLXyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),optimizer = tf.keras.optimizers.Adam(1e-4),\n",
        "             metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.853604Z",
          "iopub.status.idle": "2023-06-19T17:29:00.854090Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.853866Z",
          "shell.execute_reply": "2023-06-19T17:29:00.853887Z"
        },
        "trusted": true,
        "id": "PjkKBA1lLXyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = model.fit(train_data,epochs = 30,steps_per_epoch = len(train_data),\n",
        "                     initial_epoch = history_1.epoch[-1],\n",
        "                     validation_data = val_data,validation_steps = int(0.25*len(val_data)),\n",
        "                     callbacks = [early_stop,reduce_lr])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.855278Z",
          "iopub.status.idle": "2023-06-19T17:29:00.855736Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.855495Z",
          "shell.execute_reply": "2023-06-19T17:29:00.855515Z"
        },
        "trusted": true,
        "id": "OxfJNBJlLXyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Accuracy\",model.evaluate(val_data))\n",
        "print(\"Testing Accuracy\",model.evaluate(test_data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.858419Z",
          "iopub.status.idle": "2023-06-19T17:29:00.858897Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.858650Z",
          "shell.execute_reply": "2023-06-19T17:29:00.858671Z"
        },
        "trusted": true,
        "id": "cRLxN9LoLXyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_historys(original_history, new_history, initial_epochs):\n",
        "    \"\"\"\n",
        "    Compares two model history objects.\n",
        "    \"\"\"\n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    print(len(acc))\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    print(len(total_acc))\n",
        "    print(total_acc)\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.860111Z",
          "iopub.status.idle": "2023-06-19T17:29:00.860555Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.860330Z",
          "shell.execute_reply": "2023-06-19T17:29:00.860350Z"
        },
        "trusted": true,
        "id": "TEUD8SX6LXyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_historys(history_1,history_2,initial_epochs = 12)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.862497Z",
          "iopub.status.idle": "2023-06-19T17:29:00.862965Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.862746Z",
          "shell.execute_reply": "2023-06-19T17:29:00.862767Z"
        },
        "trusted": true,
        "id": "WIz3BCjYLXyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *  Training accuracy - 85.58%\n",
        "> *  Testing Accuracy - 77.08%\n",
        "> *  Validation Accuracy - 76.02%"
      ],
      "metadata": {
        "id": "D-hpjtvvLXyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evalutation"
      ],
      "metadata": {
        "id": "5r-xIDm6LXyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = model.predict(test_data)\n",
        "pred_probs[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.864343Z",
          "iopub.status.idle": "2023-06-19T17:29:00.864809Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.864564Z",
          "shell.execute_reply": "2023-06-19T17:29:00.864585Z"
        },
        "trusted": true,
        "id": "HMEE8P0BLXyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = pred_probs.argmax(axis =1)\n",
        "print(pred_classes[0])\n",
        "print(class_names[pred_classes[0]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.866378Z",
          "iopub.status.idle": "2023-06-19T17:29:00.866877Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.866604Z",
          "shell.execute_reply": "2023-06-19T17:29:00.866625Z"
        },
        "trusted": true,
        "id": "qV5j5_UULXyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels = []\n",
        "for image,label in test_data.unbatch():\n",
        "    y_labels.append(label.numpy().argmax())\n",
        "y_labels[:20]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.870852Z",
          "iopub.status.idle": "2023-06-19T17:29:00.871347Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.871116Z",
          "shell.execute_reply": "2023-06-19T17:29:00.871138Z"
        },
        "trusted": true,
        "id": "9D8Fu8oaLXyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pred_classes))\n",
        "print(len(y_labels))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.873042Z",
          "iopub.status.idle": "2023-06-19T17:29:00.873585Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.873348Z",
          "shell.execute_reply": "2023-06-19T17:29:00.873370Z"
        },
        "trusted": true,
        "id": "qHEczbFyLXyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Classification report\\n\",classification_report(y_labels,pred_classes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.875620Z",
          "iopub.status.idle": "2023-06-19T17:29:00.876118Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.875889Z",
          "shell.execute_reply": "2023-06-19T17:29:00.875911Z"
        },
        "trusted": true,
        "id": "nzZhTRJGLXyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_dict = classification_report(y_labels,pred_classes,output_dict = True)\n",
        "classification_dict"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.878129Z",
          "iopub.status.idle": "2023-06-19T17:29:00.878616Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.878389Z",
          "shell.execute_reply": "2023-06-19T17:29:00.878411Z"
        },
        "trusted": true,
        "id": "Gus7F2tjLXyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_f1_scores = {}\n",
        "for k,v in classification_dict.items():\n",
        "    if k == \"accuracy\":\n",
        "        break\n",
        "    else:\n",
        "        classification_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "classification_f1_scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.880065Z",
          "iopub.status.idle": "2023-06-19T17:29:00.880506Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.880292Z",
          "shell.execute_reply": "2023-06-19T17:29:00.880312Z"
        },
        "trusted": true,
        "id": "TmRY0fwCLXyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = pd.DataFrame({\"class_name\":list(classification_f1_scores.keys()),\n",
        "                         \"F1-Scores\":list(classification_f1_scores.values())})\n",
        "f1_scores.sort_values(\"F1-Scores\",ascending = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.881892Z",
          "iopub.status.idle": "2023-06-19T17:29:00.882358Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.882133Z",
          "shell.execute_reply": "2023-06-19T17:29:00.882154Z"
        },
        "trusted": true,
        "id": "_qC3LVD-LXyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> From the F1-Scores dataframe we can clearly see that our model perform best on Melanocytic Nevi with an F1-Score of 0.92 and perform the worst on Atopic Dematitis."
      ],
      "metadata": {
        "id": "k5wEGzheLXyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.884209Z",
          "iopub.status.idle": "2023-06-19T17:29:00.885073Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.884816Z",
          "shell.execute_reply": "2023-06-19T17:29:00.884851Z"
        },
        "trusted": true,
        "id": "nCqswgouLXym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_confusion_matrix(y_labels,pred_classes,classes = class_names,figsize = (20,20))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.887153Z",
          "iopub.status.idle": "2023-06-19T17:29:00.887615Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.887394Z",
          "shell.execute_reply": "2023-06-19T17:29:00.887415Z"
        },
        "trusted": true,
        "id": "eHpYAyHeLXym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* > From the confusion matrix we can clearly observe that the model is getting confused betwwen Melanocytic Nevi and Melanoma, Melanocyctic Nevi and Benign Kerotosis like Lesions, Tinea Ringworm Candidiasis and other Fungai Infections and Psoriasis pictures Lichen Planus and releated diseases.\n",
        "* > In order to examine why our model is getting confused between the above mentioned diseases we can look at the data ourselves or consult a doctor to find out whethere these disesase can be classified properly just by looking at their images, often when it comes to skin diseases it cannot be classified properly just by looking at the image further testing is required."
      ],
      "metadata": {
        "id": "sjdmEvGgLXyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let us see what our most wrong predictions are to understand more about our model's performance**"
      ],
      "metadata": {
        "id": "cW5fkcWFLXyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = []\n",
        "for filepath in test_data.list_files(\"./output/test/*/*.jpg\",\n",
        "                                     shuffle=False):\n",
        "  filepaths.append(filepath.numpy())\n",
        "filepaths[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.889422Z",
          "iopub.status.idle": "2023-06-19T17:29:00.889892Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.889643Z",
          "shell.execute_reply": "2023-06-19T17:29:00.889663Z"
        },
        "trusted": true,
        "id": "xAzgmZDwLXyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filepaths)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.894296Z",
          "iopub.status.idle": "2023-06-19T17:29:00.894796Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.894542Z",
          "shell.execute_reply": "2023-06-19T17:29:00.894563Z"
        },
        "trusted": true,
        "id": "4qGodDDuLXyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_df = pd.DataFrame({\"img_path\": filepaths,\n",
        "                        \"y_true\": y_labels,\n",
        "                        \"y_pred\": pred_classes,\n",
        "                        \"pred_conf\": pred_probs.max(axis=1), # get the maximum prediction probability value\n",
        "                        \"y_true_classname\": [class_names[i] for i in y_labels],\n",
        "                        \"y_pred_classname\": [class_names[i] for i in pred_classes]})\n",
        "prediction_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.896147Z",
          "iopub.status.idle": "2023-06-19T17:29:00.896605Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.896378Z",
          "shell.execute_reply": "2023-06-19T17:29:00.896399Z"
        },
        "trusted": true,
        "id": "ZQV05xDKLXyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_df[\"correct_pred\"] = prediction_df[\"y_true\"]==prediction_df[\"y_pred\"]\n",
        "prediction_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.898625Z",
          "iopub.status.idle": "2023-06-19T17:29:00.899106Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.898888Z",
          "shell.execute_reply": "2023-06-19T17:29:00.898910Z"
        },
        "trusted": true,
        "id": "lVJy2Q9WLXyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_50_wrong = prediction_df[prediction_df[\"correct_pred\"] == False].sort_values(\"pred_conf\", ascending=False)[:50]\n",
        "top_50_wrong.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-19T17:29:00.900520Z",
          "iopub.status.idle": "2023-06-19T17:29:00.900973Z",
          "shell.execute_reply.started": "2023-06-19T17:29:00.900756Z",
          "shell.execute_reply": "2023-06-19T17:29:00.900778Z"
        },
        "trusted": true,
        "id": "UwMa-jZ_LXyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> As we saw in our confusion matrix Benign Keratosis-Like Lesions and Melanocyctic Nevi is often misclassified by our model."
      ],
      "metadata": {
        "id": "WH2lM6ePLXyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "> Transfer Learning architecture EfficientNetB5 works pretty well on the given dataset of 10 classes of skin diseases.But some of these diseases cannot be classified correctly just by looking at the images even by doctors so our model gets confused between different classes of diseases in our data. Currently it has a testing accuracy of 77% when trained for 21 epochs and it will improve if trained for another 10-15 epochs and it may get saturated around 80-85%.\n",
        "Now if we train on certain distinguishable classes in our data instead of all the 10 classes the same EfficientNetB5 would perform extremely well."
      ],
      "metadata": {
        "id": "Y2zL9X-kLXyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "> As I mentioned after feature extractor model training the training stopped even in fine tuned model around 21 epochs when it was supposed to train for 30 epochs and again it wasn't beacuse of earlystopping. My guess so for is my CPU ran out of memory in Kaggle and I am not sure why since I have implemented mixed_precision training. I generally work in Collab on all my projects and I have never had this problem before in Collab, am I bit new in implemented Deep Learning Models in Kaggle any suggestions to solve this problem and tips to make sure this doesn't happen in the future would greatly helpful.\n",
        "\n",
        "**Thank You**"
      ],
      "metadata": {
        "id": "Ct_FYiiyLXyp"
      }
    }
  ]
}